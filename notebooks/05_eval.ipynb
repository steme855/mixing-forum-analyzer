{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title-05",
   "metadata": {},
   "source": [
    "# 05 — Evaluation (TF‑IDF & optional SBERT)\n",
    "\n",
    "Ziel: Unseren Mini‑Suchstack aus Woche 1 quantitativ prüfen.\n",
    "\n",
    "**Was wir messen**\n",
    "- *MRR* (Mean Reciprocal Rank)\n",
    "- *Precision@k* (k=1,3,5)\n",
    "- *MAP* (Mean Average Precision)\n",
    "- *Coverage* (wie oft trifft ein System überhaupt ein Relevantes in Top‑k)\n",
    "- *Latenz* (Millisekunden pro Anfrage)\n",
    "\n",
    "Optional vergleichen wir TF‑IDF gegen SBERT (falls verfügbar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8ee7e3d-82bb-4bc0-9280-67c1ca9b3939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edeabb3f-100e-44ca-b9f6-b306026bfa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import TqdmExperimentalWarning\n",
    "warnings.filterwarnings(\"ignore\", category=TqdmExperimentalWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, ['Die Snare ist zu laut und harsch', 'Kick zu weich, es fehlt der Punch'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, time, warnings, importlib.util\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "DATA = Path(\"data\"); DATA.mkdir(exist_ok=True)\n",
    "\n",
    "def load_corpus() -> List[str]:\n",
    "    p = DATA/\"sample_corpus.json\"\n",
    "    if p.exists():\n",
    "        with p.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            x = json.load(f)\n",
    "            if isinstance(x, list) and all(isinstance(t, str) for t in x):\n",
    "                return x\n",
    "    return [\n",
    "        \"Die Snare ist zu laut und harsch\",\n",
    "        \"Kick zu weich, es fehlt der Punch\",\n",
    "        \"Vocals klingen nasal, 800 Hz absenken\",\n",
    "        \"Bass maskiert die Kick, Sidechain nötig\",\n",
    "        \"S-Laute sind scharf, De-Esser einsetzen\",\n",
    "    ]\n",
    "\n",
    "corpus = load_corpus()\n",
    "len(corpus), corpus[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## Setup & Daten\n",
    "Wir laden den Korpus aus `data/sample_corpus.json`. Wenn die Datei fehlt, nutzen wir einen kleinen Fallback.  \n",
    "Für SBERT ist eine CPU‑Installation ausreichend; wenn der Import scheitert, evaluieren wir nur TF‑IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rankers",
   "metadata": {},
   "source": [
    "## Ranker definieren\n",
    "Wir bauen einen TF‑IDF‑Ranker und versuchen optional einen SBERT‑Ranker zu laden. Beide liefern `(indices, scores)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "tfidf-ranker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4], [0.5447735663555926, 0.09712682146733126, 0.0, 0.0, 0.0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(lowercase=True, ngram_range=(1,2), min_df=1)\n",
    "X = tfidf.fit_transform(corpus)\n",
    "\n",
    "def rank_tfidf(query: str, k: int = 5):\n",
    "    qv = tfidf.transform([query])\n",
    "    sims = linear_kernel(qv, X).ravel()\n",
    "    order = np.argsort(-sims)\n",
    "    topk = order[:k]\n",
    "    return topk.tolist(), sims[topk].tolist()\n",
    "\n",
    "# Sanity-Check\n",
    "rank_tfidf(\"snare zu laut\", k=min(5, len(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sbert-ranker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.try_sbert.<locals>.rank(query: str, k: int = 5)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def try_sbert(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"):\n",
    "    try:\n",
    "        if importlib.util.find_spec(\"sentence_transformers\") is None:\n",
    "            return None\n",
    "\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        import warnings\n",
    "        from tqdm import TqdmExperimentalWarning\n",
    "        warnings.filterwarnings(\"ignore\", category=TqdmExperimentalWarning)\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            model = SentenceTransformer(model_name, device=\"cpu\")\n",
    "\n",
    "        doc_emb = model.encode(corpus, normalize_embeddings=True)\n",
    "\n",
    "        def rank(query: str, k: int = 5):\n",
    "            qv = model.encode([query], normalize_embeddings=True)\n",
    "            sims = (qv @ doc_emb.T).ravel()\n",
    "            order = np.argsort(-sims)\n",
    "            topk = order[:k]\n",
    "            return topk.tolist(), sims[topk].tolist()\n",
    "\n",
    "        return rank\n",
    "    except Exception as e:\n",
    "        print(\"SBERT nicht verfügbar:\", e)\n",
    "        return None\n",
    "        \n",
    "rank_sbert = try_sbert()\n",
    "rank_sbert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gt",
   "metadata": {},
   "source": [
    "## Ground Truth (Mini‑Set)\n",
    "Kleines Mapping Query → relevante Dokument‑Indizes. Du kannst die Liste gern erweitern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "gt-code",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'snare zu laut': [0],\n",
       " 'kick zu weich': [1],\n",
       " 'vocals nasal 800 hz': [2],\n",
       " 'bass maskiert kick sidechain': [3],\n",
       " 's-laute scharf de-esser': [4]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GT: Dict[str, List[int]] = {\n",
    "    \"snare zu laut\": [0],\n",
    "    \"kick zu weich\": [1],\n",
    "    \"vocals nasal 800 hz\": [2],\n",
    "    \"bass maskiert kick sidechain\": [3],\n",
    "    \"s-laute scharf de-esser\": [4],\n",
    "}\n",
    "GT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metrics",
   "metadata": {},
   "source": [
    "## Metriken\n",
    "Wir implementieren MRR, Precision@k, AP/MAP und Coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "metrics-code",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MRR</th>\n",
       "      <th>AP@k</th>\n",
       "      <th>latency_ms</th>\n",
       "      <th>P@1</th>\n",
       "      <th>cov@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>cov@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>cov@5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tfidf</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MRR  AP@k  latency_ms  P@1  cov@1    P@3  cov@3  P@5  cov@5\n",
       "run                                                               \n",
       "tfidf  1.0   1.0       0.394  1.0    1.0  0.333    1.0  0.2    1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>query</th>\n",
       "      <th>MRR</th>\n",
       "      <th>AP@k</th>\n",
       "      <th>latency_ms</th>\n",
       "      <th>P@1</th>\n",
       "      <th>cov@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>cov@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>cov@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>snare zu laut</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.608500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>kick zu weich</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.376750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>vocals nasal 800 hz</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.346334</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>bass maskiert kick sidechain</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.322667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>s-laute scharf de-esser</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.315292</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     run                         query  MRR  AP@k  latency_ms  P@1  cov@1  \\\n",
       "0  tfidf                 snare zu laut  1.0   1.0    0.608500  1.0    1.0   \n",
       "1  tfidf                 kick zu weich  1.0   1.0    0.376750  1.0    1.0   \n",
       "2  tfidf           vocals nasal 800 hz  1.0   1.0    0.346334  1.0    1.0   \n",
       "3  tfidf  bass maskiert kick sidechain  1.0   1.0    0.322667  1.0    1.0   \n",
       "4  tfidf       s-laute scharf de-esser  1.0   1.0    0.315292  1.0    1.0   \n",
       "\n",
       "        P@3  cov@3  P@5  cov@5  \n",
       "0  0.333333    1.0  0.2    1.0  \n",
       "1  0.333333    1.0  0.2    1.0  \n",
       "2  0.333333    1.0  0.2    1.0  \n",
       "3  0.333333    1.0  0.2    1.0  \n",
       "4  0.333333    1.0  0.2    1.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def precision_at_k(relevants: List[int], retrieved: List[int], k=3) -> float:\n",
    "    R = set(relevants)\n",
    "    topk = retrieved[:k]\n",
    "    hits = sum(1 for i in topk if i in R)\n",
    "    return hits / max(1, len(topk))\n",
    "\n",
    "def reciprocal_rank(relevants: List[int], retrieved: List[int]) -> float:\n",
    "    R = set(relevants)\n",
    "    for r, idx in enumerate(retrieved, 1):\n",
    "        if idx in R:\n",
    "            return 1.0 / r\n",
    "    return 0.0\n",
    "\n",
    "def average_precision(relevants: List[int], retrieved: List[int], k=None) -> float:\n",
    "    R = set(relevants)\n",
    "    if not R:\n",
    "        return 0.0\n",
    "    ap_sum, hits = 0.0, 0\n",
    "    cut = len(retrieved) if k is None else min(k, len(retrieved))\n",
    "    for r in range(1, cut+1):\n",
    "        if retrieved[r-1] in R:\n",
    "            hits += 1\n",
    "            ap_sum += hits / r\n",
    "    return ap_sum / max(1, len(R))\n",
    "\n",
    "def evaluate_run(run_name: str, rank_fn, ks=(1,3,5)) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    rows = []\n",
    "    for q, rel in GT.items():\n",
    "        t0 = time.perf_counter()\n",
    "        idxs, _ = rank_fn(q, k=max(ks))\n",
    "        latency_ms = (time.perf_counter() - t0) * 1000\n",
    "        row = {\n",
    "            \"run\": run_name,\n",
    "            \"query\": q,\n",
    "            \"MRR\": reciprocal_rank(rel, idxs),\n",
    "            \"AP@k\": average_precision(rel, idxs, k=max(ks)),\n",
    "            \"latency_ms\": latency_ms,\n",
    "        }\n",
    "        for k_ in ks:\n",
    "            row[f\"P@{k_}\"] = precision_at_k(rel, idxs, k_)\n",
    "            row[f\"cov@{k_}\"] = float(any(i in set(rel) for i in idxs[:k_]))\n",
    "        rows.append(row)\n",
    "    df = pd.DataFrame(rows)\n",
    "    agg = df.drop(columns=[\"query\"]).groupby(\"run\").mean(numeric_only=True).round(3)\n",
    "    return df, agg\n",
    "\n",
    "# Beispiel: TF‑IDF auswerten\n",
    "tf_row, tf_agg = evaluate_run(\"tfidf\", rank_tfidf)\n",
    "display(tf_agg); tf_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "sbert-eval",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MRR</th>\n",
       "      <th>AP@k</th>\n",
       "      <th>latency_ms</th>\n",
       "      <th>P@1</th>\n",
       "      <th>cov@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>cov@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>cov@5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sbert</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MRR  AP@k  latency_ms  P@1  cov@1    P@3  cov@3  P@5  cov@5\n",
       "run                                                               \n",
       "sbert  1.0   1.0        15.5  1.0    1.0  0.333    1.0  0.2    1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if rank_sbert:\n",
    "    sb_row, sb_agg = evaluate_run(\"sbert\", rank_sbert)\n",
    "    display(sb_agg); sb_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compare-plots",
   "metadata": {},
   "source": [
    "## Vergleich (optional klein visualisiert)\n",
    "Wir kombinieren die Aggregationen (sofern SBERT vorhanden ist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "compare-code",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MRR</th>\n",
       "      <th>AP@k</th>\n",
       "      <th>latency_ms</th>\n",
       "      <th>P@1</th>\n",
       "      <th>cov@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>cov@3</th>\n",
       "      <th>P@5</th>\n",
       "      <th>cov@5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tfidf</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sbert</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MRR  AP@k  latency_ms  P@1  cov@1    P@3  cov@3  P@5  cov@5\n",
       "run                                                               \n",
       "tfidf  1.0   1.0       0.394  1.0    1.0  0.333    1.0  0.2    1.0\n",
       "sbert  1.0   1.0      15.500  1.0    1.0  0.333    1.0  0.2    1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_list = [tf_agg]\n",
    "if 'sb_agg' in globals():\n",
    "    agg_list.append(sb_agg)\n",
    "combined = pd.concat(agg_list)\n",
    "combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export",
   "metadata": {},
   "source": [
    "## Export\n",
    "Wir speichern die Detail‑Zeilen in `data/eval_details.csv` und die Aggregation in `data/eval_summary.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "export-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gespeichert in data/…\n"
     ]
    }
   ],
   "source": [
    "DATA.mkdir(exist_ok=True)\n",
    "tf_row.to_csv(DATA/\"eval_details_tfidf.csv\", index=False)\n",
    "tf_agg.to_csv(DATA/\"eval_summary_tfidf.csv\")\n",
    "if 'sb_row' in globals():\n",
    "    sb_row.to_csv(DATA/\"eval_details_sbert.csv\", index=False)\n",
    "    sb_agg.to_csv(DATA/\"eval_summary_sbert.csv\")\n",
    "print(\"Gespeichert in data/…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exercises",
   "metadata": {},
   "source": [
    "## Übungen\n",
    "1. Erweitere den Ground‑Truth um neue Queries und relevante Dokumente.\n",
    "2. Variiere TF‑IDF‑Parameter (`ngram_range`, Stopwörter, `min_df`) und beobachte MRR/Precision.\n",
    "3. Erzeuge Noisy‑Queries (z. B. Rechtschreibfehler) und vergleiche TF‑IDF vs. SBERT Robustheit.\n",
    "4. Logge Latenzen über 100 Wiederholungen (Warm/Cold) und bilde Quantile (P50/P90/P99).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc860d8c-a7c2-41d3-bc41-a288df34a75f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a139cd-5327-44a3-90d4-704d6acff3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
