{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-06-keyphrases",
   "metadata": {},
   "source": [
    "# 06 ‚Äî Keyphrases (YAKE + Fallback)\n",
    "\n",
    "In diesem Notebook extrahieren wir Keyphrases aus dem Demo‚ÄëKorpus.\n",
    "\n",
    "- **YAKE** als prim√§re Methode (Sprache: Deutsch)\n",
    "- **TF‚ÄëIDF Fallback** (2‚Äì3‚ÄëGramme), falls `yake` nicht verf√ºgbar ist\n",
    "- Robuste Pfadlogik f√ºr `./data` bzw. `../data`\n",
    "- Export als **JSON** (Liste je Post) und **CSV** (eine Phrase pro Zeile)\n",
    "\n",
    "> Tipp: Falls `yake` fehlt, kannst du im Terminal deiner venv installieren:\n",
    "> `python -m pip install yake`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "setup-paths",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö 10 Texte aus: /Users/sm/Documents/mixing-forum-analyzer/data/sample_corpus.json\n"
     ]
    }
   ],
   "source": [
    "# üîß Robustes Setup\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Finde den /data-Ordner, bevorzugt den, der die Datei enth√§lt\n",
    "CWD = Path.cwd().resolve()\n",
    "candidates = [\n",
    "    CWD / \"data\",\n",
    "    CWD.parent / \"data\",\n",
    "]\n",
    "\n",
    "DATA = None\n",
    "for d in candidates:\n",
    "    if (d / \"sample_corpus.json\").exists():\n",
    "        DATA = d\n",
    "        break\n",
    "if DATA is None:\n",
    "    raise FileNotFoundError(\"sample_corpus.json nicht gefunden unter ./data oder ../data\")\n",
    "\n",
    "SAMPLE = DATA / \"sample_corpus.json\"\n",
    "texts = json.loads(SAMPLE.read_text(encoding=\"utf-8\"))\n",
    "print(f\"üìö {len(texts)} Texte aus: {SAMPLE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "import-yake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAKE: ok\n"
     ]
    }
   ],
   "source": [
    "# YAKE importieren ‚Äì wenn nicht vorhanden, setzen wir einen Fallback-Flag\n",
    "try:\n",
    "    import yake  # type: ignore\n",
    "    HAVE_YAKE = True\n",
    "    YAKE_IMPORT_ERROR = None\n",
    "except Exception as e:\n",
    "    HAVE_YAKE = False\n",
    "    YAKE_IMPORT_ERROR = str(e)\n",
    "print(\"YAKE:\", \"ok\" if HAVE_YAKE else f\"nicht verf√ºgbar ({YAKE_IMPORT_ERROR})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "funcs-yake-tfidf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def extract_keyphrases_yake(texts: List[str], lang: str = \"de\", n: int = 3, topk: int = 10) -> List[Dict]:\n",
    "    \"\"\"YAKE: Top-`topk` Phrasen pro Text.\"\"\"\n",
    "    kw = yake.KeywordExtractor(lan=lang, n=n, top=topk)\n",
    "    return [{\"post_id\": i, \"phrases\": [k for k, _ in kw.extract_keywords(t)]} for i, t in enumerate(texts)]\n",
    "\n",
    "def extract_keyphrases_tfidf(texts: List[str], ngram_range=(2, 3), topk: int = 10) -> List[Dict]:\n",
    "    \"\"\"Fallback: TF-IDF Rangfolge f√ºr 2‚Äì3-Gramme pro Dokument.\"\"\"\n",
    "    vec = TfidfVectorizer(lowercase=True, ngram_range=ngram_range, min_df=1)\n",
    "    X = vec.fit_transform(texts)\n",
    "    feats = np.array(vec.get_feature_names_out())\n",
    "    results: List[Dict] = []\n",
    "    for i in range(X.shape[0]):\n",
    "        row = X.getrow(i)\n",
    "        if row.nnz == 0:\n",
    "            results.append({\"post_id\": i, \"phrases\": []})\n",
    "            continue\n",
    "        # Indizes der h√∂chsten TF-IDF Gewichte pro Dokument\n",
    "        order = row.indices[np.argsort(row.data)[::-1]]\n",
    "        phrases = feats[order][:topk].tolist()\n",
    "        results.append({\"post_id\": i, \"phrases\": phrases})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "run-extraction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,\n",
       " [{'post_id': 0,\n",
       "   'phrases': ['pumpt im Mix',\n",
       "    'Kickdrum pumpt',\n",
       "    'Snare wirkt',\n",
       "    'wirkt zu d√ºnn',\n",
       "    'Mix',\n",
       "    'Kickdrum',\n",
       "    'Snare',\n",
       "    'd√ºnn',\n",
       "    'pumpt',\n",
       "    'wirkt']},\n",
       "  {'post_id': 1,\n",
       "   'phrases': ['kHz Bereich',\n",
       "    'Vocals sitzen',\n",
       "    'Bereich',\n",
       "    'Pr√§senz',\n",
       "    'Vocals',\n",
       "    'hinten',\n",
       "    'kHz',\n",
       "    'sitzen']}])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if HAVE_YAKE:\n",
    "    keyphrases = extract_keyphrases_yake(texts, lang=\"de\", n=3, topk=10)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è YAKE nicht verf√ºgbar ‚Äì nutze TF-IDF Fallback (2‚Äì3-Gramme).\")\n",
    "    keyphrases = extract_keyphrases_tfidf(texts, ngram_range=(2, 3), topk=10)\n",
    "\n",
    "len(keyphrases), keyphrases[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "export-and-preview",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gespeichert: /Users/sm/Documents/mixing-forum-analyzer/data/keyphrases.json\n",
      "‚úÖ Gespeichert: /Users/sm/Documents/mixing-forum-analyzer/data/keyphrases.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>phrases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[pumpt im Mix, Kickdrum pumpt, Snare wirkt, wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[kHz Bereich, Vocals sitzen, Bereich, Pr√§senz,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[Snare klingt trocken, Snare klingt, Raumantei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[Bassdrum und Kickdrum, brauche mehr Punch, Pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[Low-Pass k√∂nnte helfen, sanfter Low-Pass, sch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                            phrases\n",
       "0        0  [pumpt im Mix, Kickdrum pumpt, Snare wirkt, wi...\n",
       "1        1  [kHz Bereich, Vocals sitzen, Bereich, Pr√§senz,...\n",
       "2        2  [Snare klingt trocken, Snare klingt, Raumantei...\n",
       "3        3  [Bassdrum und Kickdrum, brauche mehr Punch, Pu...\n",
       "4        4  [Low-Pass k√∂nnte helfen, sanfter Low-Pass, sch..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "OUT_JSON = DATA / \"keyphrases.json\"\n",
    "OUT_CSV  = DATA / \"keyphrases.csv\"\n",
    "\n",
    "# Sicherstellen, dass 'keyphrases' existiert\n",
    "if 'keyphrases' not in globals():\n",
    "    raise RuntimeError(\"Keine Variable 'keyphrases' gefunden ‚Äì bitte erst die Extraktion-Zelle ausf√ºhren.\")\n",
    "\n",
    "# JSON (Liste pro Post)\n",
    "OUT_JSON.write_text(json.dumps(keyphrases, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "# CSV (eine Phrase pro Zeile)\n",
    "rows = [{\"post_id\": item[\"post_id\"], \"phrase\": p} for item in keyphrases for p in item.get(\"phrases\", [])]\n",
    "pd.DataFrame(rows).to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(\"‚úÖ Gespeichert:\", OUT_JSON)\n",
    "print(\"‚úÖ Gespeichert:\", OUT_CSV)\n",
    "\n",
    "# Vorschau\n",
    "pd.read_json(OUT_JSON).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a72f97-a48a-4a8d-9af2-4da4e2cb6396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a9ee55-9f68-4934-9f76-0ffefb9295a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f24493f-ecdc-4c5e-84ea-11f3769206d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2e896d-d773-4d35-97dc-c3dea18e8631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785e7ad8-7da8-466b-9303-02a3206bba12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
