{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title-04",
   "metadata": {},
   "source": [
    "# 04 — spaCy (Deutsch): Tokens, Lemmata, POS, Adjektive\n",
    "\n",
    "Ziel: Den Mixing‑Korpus linguistisch untersuchen. Wir extrahieren Token, Lemmata, Wortarten (POS), Adjektive für Sound‑Beschreibungen und einfache Phrasen.\n",
    "\n",
    "**Was du lernst**\n",
    "- Robust *de_core_news_sm* laden (venv/HF‑kompatibel)\n",
    "- Tokenisierung & Lemmatisierung\n",
    "- POS‑Tags (insb. Adjektive) und Noun‑Chunks\n",
    "- Mini‑Auswertung (Top‑Adjektive, Häufigkeiten)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## Setup & Daten\n",
    "Wir laden den Korpus aus `data/sample_corpus.json`. Wenn die Datei fehlt, verwenden wir einen kleinen Fallback. spaCy laden wir robust (direkter Paket‑Import **oder** `spacy.load`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, ['Die Snare ist zu laut und harsch', 'Kick zu weich, es fehlt der Punch'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, importlib.util\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "DATA = Path(\"data\"); DATA.mkdir(exist_ok=True)\n",
    "\n",
    "def load_corpus():\n",
    "    p = DATA/\"sample_corpus.json\"\n",
    "    if p.exists():\n",
    "        with p.open(\"r\", encoding=\"utf-8\") as f:\n",
    "            x = json.load(f)\n",
    "            if isinstance(x, list) and all(isinstance(t, str) for t in x):\n",
    "                return x\n",
    "    return [\n",
    "        \"Die Snare ist zu laut und harsch\",\n",
    "        \"Kick zu weich, es fehlt der Punch\",\n",
    "        \"Vocals klingen nasal, 800 Hz absenken\",\n",
    "        \"Bass maskiert die Kick, Sidechain nötig\",\n",
    "        \"S-Laute sind scharf, De-Esser einsetzen\",\n",
    "    ]\n",
    "\n",
    "texts = load_corpus()\n",
    "len(texts), texts[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-spacy",
   "metadata": {},
   "source": [
    "## spaCy robust laden\n",
    "Wir versuchen zuerst den direkten Modul‑Import `de_core_news_sm` (funktioniert gut in virtuellen Umgebungen und auf Hugging Face). Fällt das aus, nutzen wir `spacy.load('de_core_news_sm')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spacy-load",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.de.German at 0x14f8b1b80>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_spacy_de():\n",
    "    try:\n",
    "        import spacy\n",
    "        if importlib.util.find_spec(\"de_core_news_sm\") is not None:\n",
    "            import de_core_news_sm\n",
    "            return de_core_news_sm.load()\n",
    "        return spacy.load(\"de_core_news_sm\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(\n",
    "            \"spaCy DE nicht verfügbar. Installiere lokal: \\n\"\n",
    "            \"  python -m spacy download de_core_news_sm\\n\\n\"\n",
    "            f\"Originalfehler: {e}\"\n",
    "        )\n",
    "\n",
    "nlp = load_spacy_de()\n",
    "nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inspect-one",
   "metadata": {},
   "source": [
    "## Ein Dokument inspizieren\n",
    "Wir betrachten ein Beispiel und zeigen Token mit **Lemma** und **POS**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "one-doc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Die</td>\n",
       "      <td>der</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Snare</td>\n",
       "      <td>Snare</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ist</td>\n",
       "      <td>sein</td>\n",
       "      <td>AUX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zu</td>\n",
       "      <td>zu</td>\n",
       "      <td>PART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>laut</td>\n",
       "      <td>laut</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>und</td>\n",
       "      <td>und</td>\n",
       "      <td>CCONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>harsch</td>\n",
       "      <td>harsch</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     text   lemma    pos\n",
       "0     Die     der    DET\n",
       "1   Snare   Snare   NOUN\n",
       "2     ist    sein    AUX\n",
       "3      zu      zu   PART\n",
       "4    laut    laut    ADV\n",
       "5     und     und  CCONJ\n",
       "6  harsch  harsch    ADV"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(texts[0])\n",
    "rows = [{\"text\": t.text, \"lemma\": t.lemma_, \"pos\": t.pos_} for t in doc]\n",
    "pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjectives",
   "metadata": {},
   "source": [
    "## Adjektive extrahieren (Sound‑Wörter)\n",
    "Wir holen alle Adjektive pro Dokument und bauen eine globale Häufigkeitsliste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adjectives-code",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nasal', 1)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def adjectives_per_doc(texts):\n",
    "    out = []\n",
    "    for tx in texts:\n",
    "        doc = nlp(tx)\n",
    "        adjs = [t.lemma_.lower() for t in doc if t.pos_ == \"ADJ\" and not t.is_stop]\n",
    "        out.append(adjs)\n",
    "    return out\n",
    "\n",
    "adjs_list = adjectives_per_doc(texts)\n",
    "Counter([a for lst in adjs_list for a in lst]).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noun-chunks",
   "metadata": {},
   "source": [
    "## Noun‑Chunks (einfache Phrasen)\n",
    "Praktisch, um Phrasen wie *\"mehr Raumanteil\"* zu erkennen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "noun-chunks-code",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Die Snare ist zu laut und harsch', ['Die Snare']),\n",
       " ('Kick zu weich, es fehlt der Punch', ['Kick', 'der Punch']),\n",
       " ('Vocals klingen nasal, 800 Hz absenken', ['800 Hz']),\n",
       " ('Bass maskiert die Kick, Sidechain nötig',\n",
       "  ['Bass', 'die Kick', 'Sidechain']),\n",
       " ('S-Laute sind scharf, De-Esser einsetzen', ['S-Laute', 'De-Esser'])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def noun_chunks(text):\n",
    "    doc = nlp(text)\n",
    "    return [nc.text for nc in doc.noun_chunks]\n",
    "\n",
    "[(t, noun_chunks(t)) for t in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adj-df",
   "metadata": {},
   "source": [
    "## Übersichtstabelle: Top‑Adjektive\n",
    "Aggregierte Adjektive als DataFrame, sortiert nach Häufigkeit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adj-df-code",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjective</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nasal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  adjective  count\n",
       "0     nasal      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_counts = Counter([a for lst in adjs_list for a in lst])\n",
    "adj_df = pd.DataFrame(sorted(adj_counts.items(), key=lambda x: -x[1]), columns=[\"adjective\", \"count\"])\\\n",
    "         .reset_index(drop=True)\n",
    "adj_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mini-exercises",
   "metadata": {},
   "source": [
    "## Übungen\n",
    "1. Füge 5–10 weitere Textzeilen in `data/sample_corpus.json` hinzu und beobachte, wie sich die Top‑Adjektive ändern.\n",
    "2. Filtere Adjektive nach *Sound‑Semantik* (z. B. *scharf, harsch, weich, punchy*) und zähle nur diese.\n",
    "3. Extra: Füge eine Heuristik hinzu, die *Adjektiv + Substantiv* Phrasen extrahiert (z. B. *scharfe Hi‑Hats*)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
